{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from configs.data import MACHINE_LEARNING_DATASET_PATH, MERGED_DATASET_PATH, OUT_PATH, VERSION\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from configs.enums import Column, RISKCLASSIFICATIONS\n",
    "from machine_learning.utils import scale_dataset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import shap"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76f1541520d536e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(dataframe: pd.DataFrame):\n",
    "    data_by_risk = [dataframe[dataframe[\"country_risk\"] == v] for v in RISKCLASSIFICATIONS.get_values()]\n",
    "    split_data = [\n",
    "        # Train (70%) and test (30%) datasets\n",
    "        np.split(sd.sample(frac=1, random_state=0), [int(0.7 * len(sd))])\n",
    "        for sd\n",
    "        in data_by_risk\n",
    "    ]\n",
    "\n",
    "    train = pd.concat([row[0] for row in split_data])\n",
    "    test = pd.concat([row[1] for row in split_data])\n",
    "\n",
    "    return train, test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e3ceb847fe21e0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(MACHINE_LEARNING_DATASET_PATH)\n",
    "\n",
    "train_df, test_df = split_data(df)\n",
    "\n",
    "train, x_train, train_labels = scale_dataset(train_df, oversample=True)\n",
    "test, x_test, test_labels = scale_dataset(test_df, oversample=False)  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58a22c5e76a55955"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_results(model) -> None:\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    print(\"\\n###### Training ######\")\n",
    "    print(classification_report(train_labels, y_pred_train))\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"\\n###### Test ######\")\n",
    "    print(classification_report(test_labels, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99fcae97297d061d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def output_wrong_predicted_xlsx(dataframe, y_pred, model_name):\n",
    "    import os\n",
    "    options = [\"low\", \"medium\", \"high\"]\n",
    "    \n",
    "    result = dataframe\n",
    "    result[\"predicted_country_risk\"] = y_pred\n",
    "    \n",
    "    wrongly_predicted = result[result[\"country_risk\"] != result[\"predicted_country_risk\"]]\n",
    "    \n",
    "    m_df = pd.read_excel(MERGED_DATASET_PATH)\n",
    "    wm_df = m_df.iloc[wrongly_predicted.index, ]\n",
    "    \n",
    "    match_classifications = lambda c: [(wrongly_predicted[c] == 0), (wrongly_predicted[c] == 1), (wrongly_predicted[c] == 2)]\n",
    "\n",
    "    wm_df[\"country_risk\"] = np.select(match_classifications(\"country_risk\"), options)\n",
    "    wm_df[\"predicted_country_risk\"] = np.select(match_classifications(\"predicted_country_risk\"), options)\n",
    "    \n",
    "    cols = [\"year\", \"country\"] + list(wrongly_predicted.columns) + [\"norm_risk\"]\n",
    "    wm_df = wm_df[cols]\n",
    "    wm_df.to_excel(\n",
    "            os.path.join(OUT_PATH, f\"{model_name}-wrongly-predicted-V.{VERSION}.xlsx\"),\n",
    "            index=False,\n",
    "            sheet_name=\"Data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8c0fdfc16757d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eeca891b4310b5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_model.fit(x_train, train_labels)\n",
    "\n",
    "print_results(knn_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2f44540bdf8ca63"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]  \n",
    "score_knn = cross_val_score(knn_model, X, y, cv=10)\n",
    "print(score_knn)\n",
    "print(\"Avg: \", np.average((score_knn)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22f22bad6c79758"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_pred = knn_model.predict(x_test)\n",
    "# print(classification_report(test_labels, y_pred))\n",
    "# output_wrong_predicted_xlsx(test_df, y_pred, \"knn_200\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45bd957cd966c8e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shap"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc3a14f51a9ad6d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shapify(data: pd.DataFrame, model):\n",
    "    train, test = split_data(data)\n",
    "\n",
    "    train, x_train, train_labels = scale_dataset(train, oversample=True)\n",
    "    test, x_test, test_labels = scale_dataset(test, oversample=False)\n",
    "\n",
    "    explainer = shap.KernelExplainer(model.predict, x_train)\n",
    "    shap_values = explainer.shap_values(x_test, nsamples=100)\n",
    "    # explainer.save()\n",
    "\n",
    "    return explainer, shap_values, x_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9538e802d866abdf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shap_df = df[:300]\n",
    "# \n",
    "# train, valid, test = split_data(shap_df)\n",
    "# train, X_train, train_labels = scale_dataset(train, oversample=True)\n",
    "# valid, X_valid, val_labels = scale_dataset(valid, oversample=False)\n",
    "# test, X_test, test_labels = scale_dataset(test, oversample=False)\n",
    "# \n",
    "# knn_model = KNeighborsClassifier(n_neighbors=50)\n",
    "# knn_model.fit(X_train, train_labels)\n",
    "# \n",
    "# explainer, shap_values, shap_x_test = shapify(shap_df, knn_model)\n",
    "# shap.summary_plot(shap_values, shap_x_test, feature_names=df.columns[Column.COUNTRY_RISK],\n",
    "#                   class_names=RISKCLASSIFICATIONS.get_names())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5034270cbc77264"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7bb2154ccf4ce10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(x_train, train_labels)\n",
    "\n",
    "print_results(lg_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c865575aefcdbffc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]  \n",
    "score_rf = cross_val_score(lg_model, X, y, cv=10)\n",
    "print(score_rf)\n",
    "print(\"Avg: \", np.average((score_rf)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9989b9bafe6f1d90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b649d9b36f1e440"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(x_train, train_labels)\n",
    "\n",
    "print_results(svm_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35037073811e57c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]  \n",
    "score_rf = cross_val_score(svm_model, X, y, cv=10)\n",
    "print(score_rf)\n",
    "print(\"Avg: \", np.average((score_rf)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a569a6ba7cd6f0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adfdd63248eb093b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# rf_model = RandomForestClassifier(n_estimators=3000, random_state=4098)\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=42) \n",
    "rf_model.fit(x_train, train_labels)\n",
    "\n",
    "print_results(rf_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e81ab76c8ccaf2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_pred = rf_model.predict(x_test)\n",
    "# print(classification_report(test_labels, y_pred))\n",
    "# output_wrong_predicted_xlsx(test_df, y_pred, \"rf_500\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "359cd5db746aa3d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]  \n",
    "score_rf = cross_val_score(rf_model, X, y, cv=10)\n",
    "print(score_rf)\n",
    "print(\"Avg: \", np.average((score_rf)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3027ab214e485340"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/ahmedabdulhamid/best-n-estimators-for-randomforest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=5000, random_state=42)\n",
    "rf_model.fit(x_train, train_labels)\n",
    "\n",
    "predictions = []\n",
    "for tree in rf_model.estimators_:\n",
    "    predictions.append(tree.predict_proba(x_test)[None, :])\n",
    "\n",
    "predictions = np.vstack(predictions)\n",
    "cum_mean = np.cumsum(predictions, axis=0)/np.arange(1, predictions.shape[0] + 1)[:, None, None]\n",
    "\n",
    "scores = []\n",
    "for pred in cum_mean:\n",
    "    scores.append(accuracy_score(test_labels, np.argmax(pred, axis=1)))\n",
    "    \n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(scores, linewidth=3)\n",
    "plt.xlabel('num_trees')\n",
    "plt.ylabel('accuracy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27faa0b9b8f2a776"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_pred = rf_model.predict(x_test)\n",
    "# result = test_df \n",
    "# result[\"predicted_country_risk\"] = y_pred\n",
    "# distribution = result.groupby([\"country_risk\", \"predicted_country_risk\"]).size().reset_index().rename(columns={0: 'count'})\n",
    "# print(distribution)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd60c3ca6d3b2e69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
