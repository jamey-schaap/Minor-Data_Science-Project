{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from configs.enums import RiskClassifications\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(dataframe: pd.DataFrame):\n",
    "    data_by_risk = [dataframe[dataframe[\"country_risk\"] == v] for v in RiskClassifications.get_values()]\n",
    "    split_data = [\n",
    "        # Train (60%), validation (20%) and test (20%) datasets\n",
    "        np.split(sd.sample(frac=1, random_state=0), [int(0.6 * len(sd)), int(0.8 * len(sd))])\n",
    "        for sd\n",
    "        in data_by_risk\n",
    "    ]\n",
    "\n",
    "    train = pd.concat([row[0] for row in split_data])\n",
    "    valid = pd.concat([row[1] for row in split_data])\n",
    "    test = pd.concat([row[2] for row in split_data])\n",
    "\n",
    "    return train, valid, test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11aa8f9a552b761f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717e40efcd20d79",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe: pd.DataFrame, oversample: bool = False):\n",
    "    # if target column is the last value\n",
    "    x = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "\n",
    "    if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        x, y = ros.fit_resample(x, y)\n",
    "\n",
    "    data = np.hstack((x, np.reshape(y, (-1, 1))))\n",
    "    return data, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./MachineLearning-Dataset-V1.xlsx\")\n",
    "train, valid, test = split_data(df)\n",
    "test, x_test, test_labels = scale_dataset(test, oversample=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9e3b783640832f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671ca05d0d7aa9c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _get_last_layer_units_and_activation(num_classes):\n",
    "    \"\"\"Gets the # units and activation function for the last network layer.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: int, number of classes.\n",
    "\n",
    "    # Returns\n",
    "        units, activation values.\n",
    "    \"\"\"\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "    return units, activation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae952a3bbd35069f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_history(history, num_classes):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax1.plot(history[\"loss\"], label=\"loss\")\n",
    "    ax1.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    if num_classes == 2:\n",
    "        ax1.set_ylabel(\"Binary crossentropy\")\n",
    "    else:\n",
    "        ax1.set_ylabel(\"Sparse categorical crossentropy\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history[\"acc\"], label=\"accuracy\")\n",
    "    ax2.plot(history[\"val_acc\"], label=\"val_accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3520caad832e8307"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network (CNN) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4576bd762e555588"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def cnn_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    \"\"\"Creates an instance of a CNN model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "\n",
    "    # Returns\n",
    "        A CNN model instance.\n",
    "    \"\"\"\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation=\"relu\"))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50dc5033d4b5bd1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_cnn_model(dataframe,\n",
    "                    learning_rate=1e-3,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,\n",
    "                    layers=2,\n",
    "                    units=64,\n",
    "                    dropout_rate=0.2,\n",
    "                    patience=2,\n",
    "                    verbose=2,\n",
    "                    disable_save=False,\n",
    "                    disable_plot_history=False,\n",
    "                    disable_print_report=False):\n",
    "    \"\"\"Trains CNN model on the given dataset.\n",
    "\n",
    "    # Arguments\n",
    "        dataframe: pandas dataframe containing train, test and validation data.\n",
    "        learning_rate: float, learning rate for training model.\n",
    "        epochs: int, number of epochs.\n",
    "        batch_size: int, number of samples per batch.\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of Dense layers in the model.\n",
    "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: If validation data has label values which were not seen\n",
    "            in the training data.\n",
    "    \"\"\"\n",
    "    # Get the data.\n",
    "    train, valid, test = split_data(dataframe)\n",
    "\n",
    "    train, x_train, train_labels = scale_dataset(train, oversample=True)\n",
    "    valid, x_val, val_labels = scale_dataset(valid, oversample=False)\n",
    "    test, x_test, test_labels = scale_dataset(test, oversample=False)\n",
    "\n",
    "    # Verify that validation labels are in the same range as training labels.\n",
    "    num_classes = len(np.unique(dataframe[dataframe.columns[-1]].values)) + 1\n",
    "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
    "    if len(unexpected_labels):\n",
    "        raise ValueError(\"Unexpected label values found in the validation set:\"\n",
    "                         \" {unexpected_labels}. Please make sure that the \"\n",
    "                         \"labels in the validation set are in the same range \"\n",
    "                         \"as training labels.\".format(\n",
    "                             unexpected_labels=unexpected_labels))\n",
    "\n",
    "    # Create model instance.\n",
    "    model = cnn_model(layers=layers,\n",
    "                      units=units,\n",
    "                      dropout_rate=dropout_rate,\n",
    "                      input_shape=x_train.shape[1:],\n",
    "                      num_classes=num_classes)\n",
    "\n",
    "    # Compile model with learning parameters.\n",
    "    if num_classes == 2:\n",
    "        loss = \"binary_crossentropy\"\n",
    "    else:\n",
    "        loss = \"sparse_categorical_crossentropy\"\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[\"acc\"])\n",
    "\n",
    "    # Create callback for early stopping on validation loss.\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=patience)]\n",
    "\n",
    "    # Train and validate model.\n",
    "    history = model.fit(\n",
    "            x_train,\n",
    "            train_labels,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, val_labels),\n",
    "            verbose=verbose,\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    # Print results.\n",
    "    history = history.history\n",
    "    if not disable_plot_history:\n",
    "        print(\"Validation accuracy: {acc}, loss: {loss}\".format(\n",
    "                acc=history[\"val_acc\"][-1], loss=history[\"val_loss\"][-1]))\n",
    "    \n",
    "        plot_history(history, num_classes)\n",
    "    \n",
    "    if not disable_print_report:\n",
    "        y_pred = model.predict(x_test).argmax(axis=1)\n",
    "        print(classification_report(test_labels, y_pred))\n",
    "    \n",
    "    # Save model.\n",
    "    if not disable_save:\n",
    "        model.save(os.path.join(os.environ[\"OUTPUT_PATH\"], \"Risk_factor_cnn_model.keras\"))\n",
    "        \n",
    "    return model, history[\"val_acc\"][-1], history[\"val_loss\"][-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167b007c00aea45d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tune_cnn_model(df, layers, units, dropout_rates, learning_rates):\n",
    "    least_val_loss = float('inf')\n",
    "    least_val_loss_params = []\n",
    "    \n",
    "    i = 1 \n",
    "    max = len(layers) * len(units) * len(dropout_rates) * len(learning_rates)\n",
    "    for l in layers:\n",
    "        for u in units:\n",
    "            for dr in dropout_rates:\n",
    "                for lr in learning_rates:  \n",
    "                    print(f\"[{i}/{max}] Layers: {l}; Units: {u}; Dropout rate: {dr}; Learning rate: {lr};\")\n",
    "                    \n",
    "                    model, _, _ = train_cnn_model(\n",
    "                        df, \n",
    "                        epochs=100, \n",
    "                        patience=20, \n",
    "                        layers=l, \n",
    "                        units=u,\n",
    "                        dropout_rate=dr,\n",
    "                        learning_rate=lr,\n",
    "                        verbose=0,\n",
    "                        disable_save=True,\n",
    "                        disable_plot_history=True,\n",
    "                        disable_print_report=True)\n",
    "                    \n",
    "                    val_loss, val_acc = model.evaluate(x_test, test_labels)\n",
    "                    print(f\"Loss: {val_loss}; Accuracy: {val_acc};\")\n",
    "                    if val_loss < least_val_loss:\n",
    "                        model.save(os.path.join(os.environ[\"OUTPUT_PATH\"], \"Risk_factor_mlp_model.keras\"))\n",
    "                        least_val_loss = val_loss\n",
    "                        least_val_loss_params = [l, u, dr, lr]\n",
    "                        \n",
    "                    i += 1\n",
    "                        \n",
    "    print(least_val_loss_params)\n",
    "    print(least_val_loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc74cfdd9caf2bd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tune_cnn_model(\n",
    "        df=df,\n",
    "        layers=[1], # 1, 2, 3, 4, 5, 6\n",
    "        units=[192, 224, 256], # 8, 16, 32, 64, 96, 128, 160, 192\n",
    "        dropout_rates=[0.2], # 0.2, 0.3, 0.4, 0.5\n",
    "        learning_rates=[0.001, 0.00125, 0.0015, 0.00175, 0.002], # 0.0001, 0.0005, 0.00075, 0.001, 0.00125, 0.0015, 0.00175, 0.002  \n",
    "    )\n",
    "   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b67271b9e804558"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_file = \"Adam_6_192_0.2_0.00175_0.1515021026134491_100.keras\" # \"Risk_factor_cnn_model.keras\"\n",
    "model = tf.keras.models.load_model(os.path.join(os.environ[\"OUTPUT_PATH\"], model_file))\n",
    "\n",
    "y_pred = model.predict(x_test).argmax(axis=1)\n",
    "print(classification_report(test_labels, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d317fd2c95277a6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Artificial Neural Network (ANN)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fd75204b32107be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ann_model(units, dropout_rate, input_shape, num_classes):\n",
    "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "    model.add(Dense(units=units, activation=\"relu\"))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(units=op_units, activation=op_activation))\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c040851010e0fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_ann_model(dataframe,\n",
    "                    learning_rate=1e-3,\n",
    "                    epochs=1000,\n",
    "                    batch_size=128,\n",
    "                    units=64,\n",
    "                    dropout_rate=0.2,\n",
    "                    patience=2,\n",
    "                    verbose=2,\n",
    "                    disable_save=False,\n",
    "                    disable_plot_history=False,\n",
    "                    disable_print_report=False):\n",
    "    # Get the data.\n",
    "    train, valid, test = split_data(dataframe)\n",
    "\n",
    "    train, x_train, train_labels = scale_dataset(train, oversample=True)\n",
    "    valid, x_val, val_labels = scale_dataset(valid, oversample=False)\n",
    "    test, x_test, test_labels = scale_dataset(test, oversample=False)\n",
    "\n",
    "    # Verify that validation labels are in the same range as training labels.\n",
    "    num_classes = len(np.unique(dataframe[dataframe.columns[-1]].values)) + 1\n",
    "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
    "    if len(unexpected_labels):\n",
    "        raise ValueError(\"Unexpected label values found in the validation set:\"\n",
    "                         \" {unexpected_labels}. Please make sure that the \"\n",
    "                         \"labels in the validation set are in the same range \"\n",
    "                         \"as training labels.\".format(\n",
    "                             unexpected_labels=unexpected_labels))\n",
    "\n",
    "    # Create model instance.\n",
    "    model = ann_model(\n",
    "                        units=units,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        input_shape=x_train.shape[1:],\n",
    "                        num_classes=num_classes)\n",
    "\n",
    "    # Compile model with learning parameters.\n",
    "    if num_classes == 2:\n",
    "        loss = \"binary_crossentropy\"\n",
    "    else:\n",
    "        loss = \"sparse_categorical_crossentropy\"\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[\"acc\"])\n",
    "\n",
    "    # Create callback for early stopping on validation loss.\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=patience)]\n",
    "\n",
    "    # Train and validate model.\n",
    "    history = model.fit(\n",
    "            x_train,\n",
    "            train_labels,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, val_labels),\n",
    "            verbose=verbose,\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    # Print results.\n",
    "    history = history.history\n",
    "    if not disable_plot_history:\n",
    "        print(\"Validation accuracy: {acc}, loss: {loss}\".format(\n",
    "                acc=history[\"val_acc\"][-1], loss=history[\"val_loss\"][-1]))\n",
    "    \n",
    "        plot_history(history, num_classes)\n",
    "        \n",
    "    if not disable_print_report:\n",
    "        y_pred = model.predict(x_test).argmax(axis=1)\n",
    "        print(classification_report(test_labels, y_pred))\n",
    "    \n",
    "    # Save model.\n",
    "    if not disable_save:\n",
    "        model.save(os.path.join(os.environ[\"OUTPUT_PATH\"], \"Risk_factor_ann_model.keras\"))\n",
    "        \n",
    "    return model, history[\"val_acc\"][-1], history[\"val_loss\"][-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eb340b63720bee0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tune_ann_model(df, units, dropout_rates, learning_rates):\n",
    "    least_val_loss = float('inf')\n",
    "    least_val_loss_params = []\n",
    "    \n",
    "    i = 1 \n",
    "    max = len(units) * len(dropout_rates) * len(learning_rates)\n",
    "    for u in units:\n",
    "        for dr in dropout_rates:\n",
    "            for lr in learning_rates:  \n",
    "                print(f\"[{i}/{max}] Units: {u}; Dropout rate: {dr}; Learning rate: {lr};\")\n",
    "                \n",
    "                model, _, _ = train_ann_model(\n",
    "                    df, \n",
    "                    epochs=100, \n",
    "                    patience=20, \n",
    "                    units=u,\n",
    "                    dropout_rate=dr,\n",
    "                    learning_rate=lr,\n",
    "                    verbose=0,\n",
    "                    disable_save=True,\n",
    "                    disable_plot_history=True,\n",
    "                    disable_print_report=True)\n",
    "                \n",
    "                val_loss, val_acc = model.evaluate(x_test, test_labels)\n",
    "                print(f\"Loss: {val_loss}; Accuracy: {val_acc};\")\n",
    "                if val_loss < least_val_loss:\n",
    "                    model.save(os.path.join(os.environ[\"OUTPUT_PATH\"], \"Risk_factor_mlp_model.keras\"))\n",
    "                    least_val_loss = val_loss\n",
    "                    least_val_loss_params = [u, dr, lr]\n",
    "                    \n",
    "                i += 1\n",
    "                        \n",
    "    print(least_val_loss_params)\n",
    "    print(least_val_loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c122afc22e125abf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./MachineLearning-Dataset-V1.xlsx\")\n",
    "\n",
    "model, _, _ = train_ann_model(\n",
    "                        df, \n",
    "                        epochs=100, \n",
    "                        patience=10, \n",
    "                        units=320,\n",
    "                        dropout_rate=0.2,\n",
    "                        learning_rate=0.002,\n",
    "                        verbose=2,\n",
    "                        disable_save=True)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(x_test, test_labels)\n",
    "print(f\"Loss: {val_loss}; Accuracy: {val_acc};\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52850fc89b1ef9fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tune_ann_model(df=df,\n",
    "                units=[320],\n",
    "                dropout_rates=[0.2],\n",
    "                learning_rates=[0.001, 0.002])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f7a6c5f64db7b47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bd76369075519305"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
